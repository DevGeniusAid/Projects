{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48ffbf9",
   "metadata": {},
   "source": [
    "## End to End Machine Learning Project\n",
    "The concept of an end-to-end machine learning project entails developing an interactive application that executes a trained machine learning model and generates output based on user input. This process encompasses the entire life cycle of a machine learning model. Here are the key stages involved in constructing a comprehensive application for your model:\n",
    "\n",
    "1. Data acquisition and gathering\n",
    "2. Data preprocessing and exploration\n",
    "3. Model training and assessment\n",
    "4. Model implementation\n",
    "\n",
    "Crafting an end-to-end machine learning application serves as a crucial demonstration of various skills within a single project. The subsequent section provides a comprehensive guide on how to construct an end-to-end machine learning application using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67792c",
   "metadata": {},
   "source": [
    "## End to End Machine Learning Project using Python\n",
    "I intend to use the Python streamlit framework for building a web interface that enables interaction with a machine learning model. The provided code excerpt illustrates how this machine learning model can be presented through an interactive and captivating web interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be2421",
   "metadata": {},
   "source": [
    "**Import Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6107da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import streamlit as st\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84dafe",
   "metadata": {},
   "source": [
    "**Create Web Application:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42916c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Utilizes the Streamlit library to create a simple web application for text emotion prediction.\n",
    "'''\n",
    "\n",
    "# Application title\n",
    "st.write(\"Text Emotions Prediction\")\n",
    "\n",
    "# Text input field for the user\n",
    "user_input= st.text_input(\"Enter any text: \")\n",
    "\n",
    "# Function to read data from a file\n",
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\") + 1:].strip()\n",
    "            data.append([label, text])\n",
    "    return data\n",
    "\n",
    "# Read data from a file\n",
    "file_path = 'text.txt'\n",
    "data = read_data(file_path)\n",
    "\n",
    "# Display instances\n",
    "print(\"Number of instances: {}\".format(len(data)))\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce240831",
   "metadata": {},
   "source": [
    "**Text processing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "368a0938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features for sample texts:\n",
      "========================================\n",
      "Text 1: Counter({'exploring': 1, 'new': 1, 'technologies': 1, 'is': 1, 'fascinating': 1, '.': 1})\n",
      "\n",
      "Text 2: Counter({'python': 1, 'developers': 1, 'create': 1, 'innovative': 1, 'solutions': 1, '!': 1})\n",
      "\n",
      "Text 3: Counter({'data': 1, 'science': 1, 'opens': 1, 'doors': 1, 'to': 1, 'endless': 1, 'possibilities': 1, 'data science': 1, 'science opens': 1, 'opens doors': 1, 'doors to': 1, 'to endless': 1, 'endless possibilities': 1, '.': 1})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "It defines two functions, `ngram` and `create_feature`, \n",
    "and then demonstrates their usage with some sample texts.\n",
    "'''\n",
    "# function to generate n-grams from a token\n",
    "def generate_ngrams(token, n): \n",
    "    output = []\n",
    "    for i in range(n - 1, len(token)): \n",
    "        ngram = ' '.join(token[i - n + 1:i + 1])\n",
    "        output.append(ngram) \n",
    "    return output\n",
    "\n",
    "# function to create features from the text\n",
    "def create_text_features(text, nrange=(1, 1)):\n",
    "    text_features = [] \n",
    "    text = text.lower() \n",
    "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
    "    \n",
    "    for n in range(nrange[0], nrange[1] + 1): \n",
    "        text_features += ngram(text_alphanum.split(), n)   \n",
    "        \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    text_features += ngram(text_punc.split(), 1)\n",
    "    return Counter(text_features)\n",
    "\n",
    "# Example usage:\n",
    "text1 = \"Exploring new technologies is fascinating.\"\n",
    "text2 = \"Python developers create innovative solutions!\"\n",
    "text3 = \"Data science opens doors to endless possibilities.\"\n",
    "\n",
    "# Display the features for sample texts\n",
    "print(\"features for sample texts:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Text 1: {create_text_features(text1)}\\n\")\n",
    "print(f\"Text 2: {create_text_features(text2)}\\n\")\n",
    "print(f\"Text 3: {create_text_features(text3, nrange=(1, 2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d34d907",
   "metadata": {},
   "source": [
    "**Data preparation and exploration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15898e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features example: \n",
      "========================================\n",
      "Counter({'time': 2, 'we': 2, 'met': 2, 'during': 1, 'the': 1, 'period': 1, 'of': 1, 'falling': 1, 'in': 1, 'love': 1, 'each': 1, 'that': 1, 'and': 1, 'especially': 1, 'when': 1, 'had': 1, 'not': 1, 'for': 1, 'a': 1, 'long': 1, 'during the': 1, 'the period': 1, 'period of': 1, 'of falling': 1, 'falling in': 1, 'in love': 1, 'love each': 1, 'each time': 1, 'time that': 1, 'that we': 1, 'we met': 1, 'met and': 1, 'and especially': 1, 'especially when': 1, 'when we': 1, 'we had': 1, 'had not': 1, 'not met': 1, 'met for': 1, 'for a': 1, 'a long': 1, 'long time': 1, 'during the period': 1, 'the period of': 1, 'period of falling': 1, 'of falling in': 1, 'falling in love': 1, 'in love each': 1, 'love each time': 1, 'each time that': 1, 'time that we': 1, 'that we met': 1, 'we met and': 1, 'met and especially': 1, 'and especially when': 1, 'especially when we': 1, 'when we had': 1, 'we had not': 1, 'had not met': 1, 'not met for': 1, 'met for a': 1, 'for a long': 1, 'a long time': 1, 'during the period of': 1, 'the period of falling': 1, 'period of falling in': 1, 'of falling in love': 1, 'falling in love each': 1, 'in love each time': 1, 'love each time that': 1, 'each time that we': 1, 'time that we met': 1, 'that we met and': 1, 'we met and especially': 1, 'met and especially when': 1, 'and especially when we': 1, 'especially when we had': 1, 'when we had not': 1, 'we had not met': 1, 'had not met for': 1, 'not met for a': 1, 'met for a long': 1, 'for a long time': 1, ',': 1, '.': 1})\n",
      "========================================\n",
      "Label example:\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "# function to convert label based on the items and their names\n",
    "def convert_label(item, name): \n",
    "    items = list(map(float, item.split()))\n",
    "    label = \"\"\n",
    "    for idx in range(len(items)): \n",
    "        if items[idx] == 1: \n",
    "            label += name[idx] + \" \"  \n",
    "            \n",
    "    return label.strip()\n",
    "\n",
    "# list of emotions\n",
    "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "\n",
    "# creating X and y lists for all instances\n",
    "X_all = []\n",
    "y_all = []\n",
    "for label, text in data:\n",
    "    y_all.append(convert_label(label, emotions))\n",
    "    X_all.append(create_text_features(text, nrange=(1, 4)))\n",
    "\n",
    "# print an example of features and label\n",
    "print(\"Features example: \")\n",
    "print(\"=\" * 40)\n",
    "print(X_all[0])\n",
    "print(\"=\" * 40)\n",
    "print(\"Label example:\")\n",
    "print(y_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2682f5b",
   "metadata": {},
   "source": [
    "**Split the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4ee8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pplit the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=123)\n",
    "\n",
    "# Function to train and test classifiers\n",
    "def train_test_classifier(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    train_predictions = clf.predict(X_train)\n",
    "    test_predictions = clf.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffe828",
   "metadata": {},
   "source": [
    "**Feature Extraction and Classifier Initialization in Scikit-Learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "093c59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DictVectorizer for feature extraction\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Initialize DictVectorizer for feature extraction\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "\n",
    "# Transform training and testing data\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define classifiers\n",
    "support_vector_classifier = SVC()\n",
    "linear_support_vector_classifier = LinearSVC(random_state=123, max_iter=1000)\n",
    "random_forest_classifier = RandomForestClassifier(random_state=123)\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21bfe3",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08850cf8",
   "metadata": {},
   "source": [
    "**Classifier Evaluation, Label Frequency Analysis, and Emotion Prediction with Emoji**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0b8e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Classifier                | Training Accuracy | Test Accuracy |\n",
      "| ------------------------- | ----------------- | ------------- |\n",
      "| SVC                       |         0.9067513 |     0.4512032 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nelio\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nelio\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LinearSVC                 |         0.9988302 |     0.5768717 |\n",
      "| RandomForestClassifier    |         0.9988302 |     0.5541444 |\n",
      "| DecisionTreeClassifier    |         0.9988302 |     0.4612299 |\n",
      "guilt     (1. 0. 0. 0. 0. 0. 0.)  1057\n",
      "guilt     (0. 0. 1. 0. 0. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 1. 0. 0. 0.)  1057\n",
      "guilt     (0. 1. 0. 0. 0. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 1. 0.)  1057\n"
     ]
    }
   ],
   "source": [
    "# List of classifiers\n",
    "classifiers = [svc, lsvc, rforest, dtree]\n",
    "\n",
    "# Train and test classifiers, and print the results\n",
    "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
    "\n",
    "for clf in classifiers: \n",
    "    clf_name = clf.__class__.__name__\n",
    "    train_accuracy, test_accuracy = train_test_classifier(clf, X_train, X_test, y_train, y_test)\n",
    "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_accuracy, test_accuracy))\n",
    "\n",
    "# Get the frequency of each label\n",
    "labels = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "labels.sort()\n",
    "label_freq = {}\n",
    "for label, _ in data: \n",
    "    label_freq[label] = label_freq.get(label, 0) + 1\n",
    "\n",
    "# Print the labels and their counts in sorted order \n",
    "for labels in sorted(label_freq, key=label_freq.get, reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(label, emotions), labels, label_freq[label]))\n",
    "\n",
    "# Dictionary for mapping emotions to emojis\n",
    "emoji_dict = {\"joy\": \"😂\", \"fear\": \"😱\", \"anger\": \"😠\", \"sadness\": \"😢\", \"disgust\": \"😒\", \"shame\": \"😳\", \"guilt\": \"😳\"}\n",
    "\n",
    "# List of texts\n",
    "texts = [t1]\n",
    "for text in texts: \n",
    "    features = create_feature(text, nrange=(1, 4))\n",
    "    features_transformed = vectorizer.transform(features)\n",
    "    prediction = clf.predict(features_transformed)[0]\n",
    "    st.write(emoji_dict[prediction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6165f3",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff37287",
   "metadata": {},
   "source": [
    "**Streamlit Application Execution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes the Streamlit application defined in the test.py file.\n",
    "!streamlit run test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d44ab2",
   "metadata": {},
   "source": [
    "So as you can see a user input in the output, simply write a text to predict the emotion of that text and hit enter. The interface will take the same time to run as the time taken by your Python file. After executing the model on the user input it will print the emotion of the text entered by the user.\n",
    "\n",
    "## Summary\n",
    "In this article, I introduced you to how to build an interactive web interface to create an end-to-end machine learning application. The streamlit framework offers a lot of features to make your web interface more interactive and user friendly that you can learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec415818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
